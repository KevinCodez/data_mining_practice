{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Mining Practice Project\n",
    "\n",
    "#### This project was written by:\n",
    "- Kyrsti Fitts\n",
    "- Shivani Merchant\n",
    "- Kevin Reynolds\n",
    "- Ryan Espejo\n",
    "\n",
    "#### Run Setup\n",
    "- Use the most recent versions of Pandas and Scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "##### Step 1: Load the data\n",
    "- For the first step of this project, we will load the data from the data files.\n",
    "- The data will be loaded into a pandas data frame.\n",
    "- The data frame will be the data structure that holds our data.\n",
    "- Add attribute name rows for the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import Binarizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
    "\n",
    "# Load the data (replace with the actual paths to your data files) and create attribute name row\n",
    "attribute_names = ['age', 'workclass', 'fnlwgt', 'education', 'education-num', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'hours-per-week', 'native-country', 'class']\n",
    "training_data = pd.read_csv('adult/training_data.csv', names = attribute_names)\n",
    "test_data = pd.read_csv('adult/test_data.csv', names=attribute_names)\n",
    "\n",
    "# Print number of rows and colums\n",
    "training_rows_length, training_columns_length = training_data.shape\n",
    "test_rows_length, test_columns_length = test_data.shape\n",
    "\n",
    "\n",
    "print(f\"Training Data Set: Read in {training_rows_length} rows and {training_columns_length} columns\")\n",
    "print(f\"Test Data Set: Read in {test_rows_length} rows and {test_columns_length} columns\")\n",
    "print(training_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "#### Step 1 Continued: Remove rows containing unknown data\n",
    "- Replace '?' characters with pandas 'NA' objects.\n",
    "- Use the \"dropna()\" method to remove the rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove records with unknown \"?\" values\n",
    "training_data = training_data.replace(' ?', pd.NA)\n",
    "training_data = training_data.dropna()\n",
    "\n",
    "test_data = test_data.replace(' ?', pd.NA)\n",
    "test_data = test_data.dropna()\n",
    "\n",
    "# Remove period from income in the test data\n",
    "test_data = test_data.replace(' <=50K.', ' <=50K')\n",
    "test_data = test_data.replace(' >50K.', ' >50K')\n",
    "\n",
    "# Display results\n",
    "print(f\"Training Data Set: Removed {training_rows_length - training_data.shape[0]} rows containing unknown values\")\n",
    "print(f\"Test Data Set: Removed {test_rows_length - test_data.shape[0]} rows containing unknown values\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1 Continued: Remove All Continuous Attributes\n",
    "- Continuous Attrbutes: age, fnlwgt, education-num, capital-gain, capital-loss, hours-per-week\n",
    "- Drop these attributes from both pandas data frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training dataset columns before continuous attribute deletion\")\n",
    "print(training_data.columns)\n",
    "print(\"Test dataset columns before continuous attribute deletion\")\n",
    "print(test_data.columns)\n",
    "\n",
    "training_data.drop('age',inplace = True, axis=1)\n",
    "training_data.drop('fnlwgt',inplace = True, axis=1)\n",
    "training_data.drop('education-num',inplace = True, axis=1)\n",
    "training_data.drop('capital-gain',inplace = True, axis=1)\n",
    "training_data.drop('capital-loss',inplace = True, axis=1)\n",
    "training_data.drop('hours-per-week',inplace = True, axis=1)\n",
    "\n",
    "test_data.drop('age',inplace = True, axis=1)\n",
    "test_data.drop('fnlwgt',inplace = True, axis=1)\n",
    "test_data.drop('education-num',inplace = True, axis=1)\n",
    "test_data.drop('capital-gain',inplace = True, axis=1)\n",
    "test_data.drop('capital-loss',inplace = True, axis=1)\n",
    "test_data.drop('hours-per-week',inplace = True, axis=1)\n",
    "\n",
    "print(\"Training dataset columns after continuous atribute deletion\")\n",
    "print(training_data.columns)\n",
    "print(\"Test dataset columns after continuous atribute deletion\")\n",
    "print(test_data.columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1 Continued: Use one-hot encoding to transform data on each multi-domain categorial attribute\n",
    "- Using scikit-learn to one-hot encode all the categorical data into numerical data so that it can be used in the algorithms for the next steps\n",
    "- doing this on the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One hot encoding on the training and test data\n",
    "training_data = pd.get_dummies(training_data)\n",
    "test_data = pd.get_dummies(test_data)\n",
    "\n",
    "# Printing new data head with encoded categorical data\n",
    "print(\"Training Data:\")\n",
    "print(training_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "##### Step 2: Build a decision tree classifier\n",
    "- Separate the targets (income) into two separate dataframes\n",
    "- X_train = all columns except income\n",
    "- Y_train = only the income columns\n",
    "- Create and fit the decision tree classifier\n",
    "- Print a classification report\n",
    "- Print a confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the target variables in training_data\n",
    "X_train = training_data.drop(columns=[\"class_ <=50K\", \"class_ >50K\"])\n",
    "y_train = training_data[[\"class_ <=50K\", \"class_ >50K\"]]\n",
    "\n",
    "# Separate the target variables in test_data\n",
    "X_test = test_data.drop(columns=[\"class_ <=50K\", \"class_ >50K\"])\n",
    "y_test = test_data[[\"class_ <=50K\", \"class_ >50K\"]].idxmax(axis=1)\n",
    "\n",
    "# Add missing column and match order\n",
    "X_test['native-country_ Holand-Netherlands'] = 0\n",
    "X_test = X_test[X_train.columns]\n",
    "\n",
    "# Create a decision tree classifier and fit it to the training data\n",
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict the targets of the test data\n",
    "y_test_prediction = clf.predict(X_test)\n",
    "\n",
    "# Get the index of the maximum value in each row to get the predicted class labels\n",
    "y_test_prediction = pd.DataFrame(y_test_prediction, columns=[\"class_ <=50K\", \"class_ >50K\"]).idxmax(axis=1)\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(y_test, y_test_prediction))\n",
    "\n",
    "# Create confusion matrix\n",
    "cm = confusion_matrix(y_test, y_test_prediction, labels=y_test.unique())\n",
    "\n",
    "# Print the confusion matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "\n",
    "print(\"\\n\" + str(cm[0][0])+ \" -> Accurately predicted income >50K\")\n",
    "print(str(cm[1][1]) + \" -> Accurately predicted income <=50K\")\n",
    "print(str(cm[1][0]) + \" -> Incorrectly predicted income to be >50K when it was actually <=50K\")\n",
    "print(str(cm[0][1]) + \" -> Incorrectly predicted income to be <=50K when is was actually >50k\")\n",
    "\n",
    "# More fancy way of displaying the matrix graphically\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "##### Step 3: Build a Naive Bayesian Classifier\n",
    "- Separate the targets (income) into two separate dataframes\n",
    "- X_train_nb = all columns except income\n",
    "- Y_train_nb = only one income column\n",
    "- Create and fit the naive bayesian classifier\n",
    "- Print a classification report\n",
    "- Print a confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the target variables in training_data\n",
    "X_train_nb = training_data.drop(columns=[\"class_ <=50K\", \"class_ >50K\"])\n",
    "y_train_nb = training_data[\"class_ <=50K\"]\n",
    "\n",
    "# Separate the target variables in test_data\n",
    "X_test_nb = test_data.drop(columns=[\"class_ <=50K\", \"class_ >50K\"])\n",
    "y_test_nb = test_data[\"class_ <=50K\"]\n",
    "\n",
    "# Add missing column and match order\n",
    "X_test_nb['native-country_ Holand-Netherlands'] = 0\n",
    "X_test_nb = X_test_nb[X_train_nb.columns]\n",
    "\n",
    "# Create a Naive Bayesian Classifier and fit it to the training data\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train_nb, y_train_nb)\n",
    "\n",
    "# Predict the targets of the test data\n",
    "y_test_prediction_nb = clf.predict(X_test_nb)\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(y_test_nb, y_test_prediction_nb))\n",
    "\n",
    "# Create confusion matrix\n",
    "cm_nb = confusion_matrix(y_test_nb, y_test_prediction_nb, labels=y_test_nb.unique())\n",
    "\n",
    "# Print the confusion matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm_nb)\n",
    "\n",
    "print(\"\\n\" + str(cm_nb[0][0])+ \" -> Accurately predicted income >50K\")\n",
    "print(str(cm_nb[1][1]) + \" -> Accurately predicted income <=50K\")\n",
    "print(str(cm_nb[1][0]) + \" -> Incorrectly predicted income to be >50K when it was actually <=50K\")\n",
    "print(str(cm_nb[0][1]) + \" -> Incorrectly predicted income to be <=50K when is was actually >50k\")\n",
    "\n",
    "# More fancy way of displaying the matrix graphically\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm_nb)\n",
    "disp.plot()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 4: Setting up for task 2 by loading data and removing records with unknown (?) values\n",
    "- Replace '?' characters with pandas 'NA' objects.\n",
    "- Use the \"dropna()\" method to remove the rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_2 = pd.read_csv('adult/training_data.csv', names = attribute_names)\n",
    "test_data_2 = pd.read_csv('adult/test_data.csv', names=attribute_names)\n",
    "\n",
    "# Print number of rows and colums\n",
    "training_rows_length, training_columns_length = training_data_2.shape\n",
    "test_rows_length, test_columns_length = test_data_2.shape\n",
    "\n",
    "\n",
    "print(f\"Training Data Set: Read in {training_rows_length} rows and {training_columns_length} columns\")\n",
    "print(f\"Test Data Set: Read in {test_rows_length} rows and {test_columns_length} columns\")\n",
    "\n",
    "# Remove records with unknown \"?\" values\n",
    "training_data_2 = training_data_2.replace(' ?', pd.NA)\n",
    "training_data_2 = training_data_2.dropna()\n",
    "\n",
    "test_data_2 = test_data_2.replace(' ?', pd.NA)\n",
    "test_data_2 = test_data_2.dropna()\n",
    "\n",
    "# Remove period from income in the test data\n",
    "test_data_2 = test_data_2.replace(' <=50K.', ' <=50K')\n",
    "test_data_2 = test_data_2.replace(' >50K.', ' >50K')\n",
    "\n",
    "print(test_data_2['class'])\n",
    "\n",
    "# Display results\n",
    "print(f\"Training Data Set: Removed {training_rows_length - training_data_2.shape[0]} rows containing unknown values\")\n",
    "print(f\"Test Data Set: Removed {test_rows_length - test_data_2.shape[0]} rows containing unknown values\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 4 Continued: Keep setting up for task 2 by using one-hot encoding and the mean value to transform the fresh data\n",
    "- Using scikit-learn to one-hot encode all the categorical data into numerical data so that it can be used in the algorithms for the next steps\n",
    "- Use mean value for the continuous attributes to convert the numerical values into binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One hot encoding on the training and test data\n",
    "training_data_2 = pd.get_dummies(training_data_2)\n",
    "test_data_2 = pd.get_dummies(test_data_2)\n",
    "\n",
    "test_data_2['native-country_ Holand-Netherlands'] = 0\n",
    "test_data_2 = test_data_2[training_data_2.columns]\n",
    "\n",
    "# Pick the columns to binarize\n",
    "columns_to_binarize = ['age','education-num','capital-gain','capital-loss','hours-per-week']\n",
    "\n",
    "# Calculate the mean values for each feature (column)\n",
    "training_means = training_data_2[columns_to_binarize].mean()\n",
    "testing_means = test_data_2[columns_to_binarize].mean()\n",
    "\n",
    "for column in columns_to_binarize:\n",
    "    training_binarizer = Binarizer(threshold=training_means[column])\n",
    "    testing_binarizer = Binarizer(threshold=testing_means[column])\n",
    "\n",
    "    training_data_2[column] = training_binarizer.transform(training_data_2[[column]].values)\n",
    "    test_data_2[column] = testing_binarizer.transform(test_data_2[[column]].values)\n",
    "\n",
    "# Printing new data head with transformed data\n",
    "print(\"Training Data:\")\n",
    "print(training_data_2.head())\n",
    "print(\"Testing Data:\")\n",
    "print(test_data_2.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 5: K-means Clustering\n",
    "- Use K-means to cluster data\n",
    "- Print centroids of the clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_values = [3, 5, 10]\n",
    "for k in k_values:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=0, n_init=10).fit(training_data_2)\n",
    "    centroids = kmeans.cluster_centers_\n",
    "    print(f\"\\nCentroids for k={k}:\")\n",
    "    print(centroids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 6: kNN Algorithm\n",
    "- Separate the targets (income) into two separate dataframes\n",
    "- X_train = all columns except income\n",
    "- Y_train = only one income column\n",
    "- Create and fit the kNN algorithm\n",
    "- Print the three prediction accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "k_values = [3, 5, 10]\n",
    "for k in k_values:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "\n",
    "    X_train = training_data_2.drop(columns=[\"class_ <=50K\", \"class_ >50K\"]).to_numpy()\n",
    "    y_train = training_data_2[\"class_ <=50K\"].to_numpy()\n",
    "    \n",
    "    X_test = test_data_2.tail(10).drop(columns=[\"class_ <=50K\", \"class_ >50K\"]).to_numpy()\n",
    "    y_test = test_data_2.tail(10)[\"class_ <=50K\"].to_numpy()\n",
    "\n",
    "    # Fit the kNN model\n",
    "    knn.fit(X_train, y_train)\n",
    "\n",
    "    # Predict on the test data\n",
    "    y_pred = knn.predict(X_test)\n",
    "\n",
    "    # Calculate and print accuracy\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"Prediction Accuracy for k={k}: {accuracy}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 7: SVM Classifier\n",
    "- Separate the targets (income) into two separate dataframes\n",
    "- X_train_svm = all columns except income\n",
    "- Y_train_svm = only one income column\n",
    "- Create and fit to the SVM Classifier\n",
    "- Print the prediction accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "# Split the dataset into features (X) and labels (y)\n",
    "X_train_svm = training_data_2.drop(columns=[\"class_ <=50K\", \"class_ >50K\"])\n",
    "y_train_svm = training_data_2[\"class_ <=50K\"]\n",
    "\n",
    "X_test_svm = test_data_2.drop(columns=[\"class_ <=50K\", \"class_ >50K\"])\n",
    "y_test_svm = test_data_2[\"class_ <=50K\"]\n",
    "\n",
    "# Create an SVM classifier \n",
    "svm_classifier = SVC()\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "svm_classifier.fit(X_train_svm, y_train_svm)\n",
    "\n",
    "# Predict on the test data\n",
    "y_pred_svm = svm_classifier.predict(X_test_svm)\n",
    "\n",
    "# Calculate and print the accuracy\n",
    "accuracy = accuracy_score(y_test_svm, y_pred_svm)\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 8: Neural Network Classifier\n",
    "- Define a simple neural network model with an input layer\n",
    "- Train the model on the training data.\n",
    "- Make predictions on the test data.\n",
    "- Calculate the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X_train_nn = training_data_2.drop(columns=[\"class_ <=50K\", \"class_ >50K\"])\n",
    "y_train_nn = training_data_2[\"class_ <=50K\"]\n",
    "\n",
    "X_test_nn = test_data_2.drop(columns=[\"class_ <=50K\", \"class_ >50K\"])\n",
    "y_test_nn = test_data_2[\"class_ <=50K\"]\n",
    "\n",
    "# Create a neural network classifier\n",
    "nn_classifier = MLPClassifier(max_iter=1000, random_state=42)\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "nn_classifier.fit(X_train_nn, y_train_nn)\n",
    "\n",
    "# Predict on the test data\n",
    "y_pred_nn = (nn_classifier.predict(X_test_nn) > 0.5).astype(int)\n",
    "\n",
    "# Calculate and print the accuracy\n",
    "accuracy_nn = accuracy_score(y_test_nn, y_pred_nn)\n",
    "print(f\"Accuracy of Neural Network Classifier: {accuracy_nn * 100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
